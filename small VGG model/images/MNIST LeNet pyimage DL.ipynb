{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(numChannels, imgRows, imgCols, numClasses,\n",
    "\t\tactivation=\"relu\", weightsPath=None):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (imgRows, imgCols, numChannels)\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (numChannels, imgRows, imgCols)\n",
    "            \n",
    "\t\t# define the first set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Conv2D(20, 5, padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "\t\t# define the second set of CONV => ACTIVATION => POOL layers\n",
    "\t\tmodel.add(Conv2D(50, 5, padding=\"same\"))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "\t\t# define the first FC => ACTIVATION layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(500))\n",
    "\t\tmodel.add(Activation(activation))\n",
    "\n",
    "\t\t# define the second FC layer\n",
    "\t\tmodel.add(Dense(numClasses))\n",
    "\n",
    "\t\t# lastly, define the soft-max classifier\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "        \n",
    "\t\t# if a weights path is supplied (inicating that the model was\n",
    "\t\t# pre-trained), then load the weights\n",
    "\t\tif weightsPath is not None:\n",
    "\t\t\tmodel.load_weights(weightsPath)\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#from pyimagesearch.cnn.networks.lenet import LeNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] downloading MNIST...\n",
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 32s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# grab the MNIST dataset (if this is your first time running this\n",
    "# script, the download may take a minute -- the 55MB MNIST dataset\n",
    "# will be downloaded)\n",
    "print(\"[INFO] downloading MNIST...\")\n",
    "((trainData, trainLabels), (testData, testLabels)) = mnist.load_data()\n",
    "\n",
    "# if we are using \"channels first\" ordering, then reshape the\n",
    "# design matrix such that the matrix is:\n",
    "# num_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainData = trainData.reshape((trainData.shape[0], 1, 28, 28))\n",
    "\ttestData = testData.reshape((testData.shape[0], 1, 28, 28))\n",
    "\n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainData = trainData.reshape((trainData.shape[0], 28, 28, 1))\n",
    "\ttestData = testData.reshape((testData.shape[0], 28, 28, 1))\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "trainData = trainData.astype(\"float32\") / 255.0\n",
    "testData = testData.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# transform the training and testing labels into vectors in the\n",
    "# range [0, classes] -- this generates a vector for each label,\n",
    "# where the index of the label is set to `1` and all other entries\n",
    "# to `0`; in the case of MNIST, there are 10 class labels\n",
    "trainLabels = np_utils.to_categorical(trainLabels, 10)\n",
    "testLabels = np_utils.to_categorical(testLabels, 10)\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.01)\n",
    "model = LeNet.build(numChannels=1, imgRows=28, imgCols=28,\n",
    "\tnumClasses=10,\n",
    "\tweightsPath= None)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training...\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 511s 9ms/step - loss: 0.9651 - accuracy: 0.7407\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 333s 6ms/step - loss: 0.2550 - accuracy: 0.9245\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.1802 - accuracy: 0.9463\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.1408 - accuracy: 0.9585\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.1164 - accuracy: 0.9663\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.1002 - accuracy: 0.9707\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 168s 3ms/step - loss: 0.0892 - accuracy: 0.9734\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0802 - accuracy: 0.9757\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0732 - accuracy: 0.9781\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0676 - accuracy: 0.9801\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0633 - accuracy: 0.9814\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0592 - accuracy: 0.9825\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 177s 3ms/step - loss: 0.0554 - accuracy: 0.9832\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0521 - accuracy: 0.9840\n",
      "Epoch 15/20\n",
      " 1152/60000 [..............................] - ETA: 2:48 - loss: 0.0637 - accuracy: 0.9844"
     ]
    }
   ],
   "source": [
    "# only train and evaluate the model if we *are not* loading a\n",
    "# pre-existing model\n",
    "#if args[\"load_model\"] < 0:\n",
    "print(\"[INFO] training...\")\n",
    "model.fit(trainData, trainLabels, batch_size=128, epochs=20,\n",
    "\tverbose=1)\n",
    "\n",
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels,\n",
    "\tbatch_size=128, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
