{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "        \n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "        \n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "        \n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "        \n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "            \n",
    "\t\t# CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\t\t# (CONV => RELU) * 2 => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\t\t# (CONV => RELU) * 3 => POOL layer set\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "        \n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "        \n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator #data augmentation\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "# grab the image paths and randomly shuffle them\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images(\"animals/\")))\n",
    "random.seed(40)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, resize it to 64x64 pixels (the required input\n",
    "\t# spatial dimensions of SmallVGGNet), and store the image in the\n",
    "\t# data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (64, 64))\n",
    "\tdata.append(image)\n",
    "    \n",
    "\t# extract the class label from the image path and update the\n",
    "\t# labels list\n",
    "    \n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\tlabels.append(label)\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "\n",
    "model = SmallVGGNet.build(width=64, height=64, depth=3,classes=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/75\n",
      "70/70 [==============================] - 105s 2s/step - loss: 1.4305 - accuracy: 0.5261 - val_loss: 1.9043 - val_accuracy: 0.3213\n",
      "Epoch 2/75\n",
      "70/70 [==============================] - 90s 1s/step - loss: 1.0578 - accuracy: 0.5712 - val_loss: 1.7358 - val_accuracy: 0.3200\n",
      "Epoch 3/75\n",
      "70/70 [==============================] - 93s 1s/step - loss: 0.9341 - accuracy: 0.6177 - val_loss: 2.3543 - val_accuracy: 0.3240\n",
      "Epoch 4/75\n",
      "70/70 [==============================] - 93s 1s/step - loss: 0.8781 - accuracy: 0.6100 - val_loss: 2.3610 - val_accuracy: 0.3800\n",
      "Epoch 5/75\n",
      "70/70 [==============================] - 91s 1s/step - loss: 0.7947 - accuracy: 0.6289 - val_loss: 1.9627 - val_accuracy: 0.4133\n",
      "Epoch 6/75\n",
      "70/70 [==============================] - 92s 1s/step - loss: 0.7668 - accuracy: 0.6289 - val_loss: 1.5321 - val_accuracy: 0.4227\n",
      "Epoch 7/75\n",
      "70/70 [==============================] - 93s 1s/step - loss: 0.7279 - accuracy: 0.6605 - val_loss: 0.7348 - val_accuracy: 0.6560\n",
      "Epoch 8/75\n",
      "70/70 [==============================] - 93s 1s/step - loss: 0.7059 - accuracy: 0.6596 - val_loss: 0.7889 - val_accuracy: 0.6387\n",
      "Epoch 9/75\n",
      "70/70 [==============================] - 90s 1s/step - loss: 0.7135 - accuracy: 0.6592 - val_loss: 0.6242 - val_accuracy: 0.7000\n",
      "Epoch 10/75\n",
      "70/70 [==============================] - 91s 1s/step - loss: 0.6952 - accuracy: 0.6655 - val_loss: 0.6057 - val_accuracy: 0.7040\n",
      "Epoch 11/75\n",
      "70/70 [==============================] - 95s 1s/step - loss: 0.6677 - accuracy: 0.6858 - val_loss: 0.6133 - val_accuracy: 0.7147\n",
      "Epoch 12/75\n",
      "70/70 [==============================] - 92s 1s/step - loss: 0.6436 - accuracy: 0.6964 - val_loss: 0.6335 - val_accuracy: 0.6920\n",
      "Epoch 13/75\n",
      "70/70 [==============================] - 92s 1s/step - loss: 0.6460 - accuracy: 0.6808 - val_loss: 0.7872 - val_accuracy: 0.6720\n",
      "Epoch 14/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.6280 - accuracy: 0.7067 - val_loss: 0.6702 - val_accuracy: 0.6787\n",
      "Epoch 15/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.6216 - accuracy: 0.6987 - val_loss: 0.6009 - val_accuracy: 0.6893\n",
      "Epoch 16/75\n",
      "70/70 [==============================] - 92s 1s/step - loss: 0.6610 - accuracy: 0.6903 - val_loss: 0.6262 - val_accuracy: 0.7013\n",
      "Epoch 17/75\n",
      "70/70 [==============================] - 91s 1s/step - loss: 0.6065 - accuracy: 0.7164 - val_loss: 0.9646 - val_accuracy: 0.6280\n",
      "Epoch 18/75\n",
      "70/70 [==============================] - 91s 1s/step - loss: 0.6049 - accuracy: 0.7137 - val_loss: 0.5870 - val_accuracy: 0.7227\n",
      "Epoch 19/75\n",
      "70/70 [==============================] - 91s 1s/step - loss: 0.6069 - accuracy: 0.7115 - val_loss: 1.1984 - val_accuracy: 0.5680\n",
      "Epoch 20/75\n",
      "70/70 [==============================] - 90s 1s/step - loss: 0.5912 - accuracy: 0.7236 - val_loss: 0.7564 - val_accuracy: 0.6920\n",
      "Epoch 21/75\n",
      "70/70 [==============================] - 91s 1s/step - loss: 0.6258 - accuracy: 0.7164 - val_loss: 0.5997 - val_accuracy: 0.7120\n",
      "Epoch 22/75\n",
      "70/70 [==============================] - 94s 1s/step - loss: 0.5808 - accuracy: 0.7155 - val_loss: 0.6837 - val_accuracy: 0.7040\n",
      "Epoch 23/75\n",
      "70/70 [==============================] - 92s 1s/step - loss: 0.5698 - accuracy: 0.7335 - val_loss: 0.8851 - val_accuracy: 0.6573\n",
      "Epoch 24/75\n",
      "70/70 [==============================] - 94s 1s/step - loss: 0.5816 - accuracy: 0.7304 - val_loss: 0.8381 - val_accuracy: 0.6467\n",
      "Epoch 25/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.5609 - accuracy: 0.7367 - val_loss: 0.5880 - val_accuracy: 0.7187\n",
      "Epoch 26/75\n",
      "70/70 [==============================] - 93s 1s/step - loss: 0.5665 - accuracy: 0.7336 - val_loss: 0.5575 - val_accuracy: 0.7387\n",
      "Epoch 27/75\n",
      "70/70 [==============================] - 93s 1s/step - loss: 0.5720 - accuracy: 0.7372 - val_loss: 0.5615 - val_accuracy: 0.7467\n",
      "Epoch 28/75\n",
      "70/70 [==============================] - 94s 1s/step - loss: 0.5756 - accuracy: 0.7241 - val_loss: 0.5468 - val_accuracy: 0.7373\n",
      "Epoch 29/75\n",
      "70/70 [==============================] - 94s 1s/step - loss: 0.5417 - accuracy: 0.7558 - val_loss: 0.5553 - val_accuracy: 0.7360\n",
      "Epoch 30/75\n",
      "70/70 [==============================] - 94s 1s/step - loss: 0.5780 - accuracy: 0.7277 - val_loss: 0.6295 - val_accuracy: 0.7040\n",
      "Epoch 31/75\n",
      "70/70 [==============================] - 93s 1s/step - loss: 0.5564 - accuracy: 0.7441 - val_loss: 0.5529 - val_accuracy: 0.7427\n",
      "Epoch 32/75\n",
      "70/70 [==============================] - 94s 1s/step - loss: 0.5552 - accuracy: 0.7349 - val_loss: 0.6319 - val_accuracy: 0.7133\n",
      "Epoch 33/75\n",
      "70/70 [==============================] - 95s 1s/step - loss: 0.5445 - accuracy: 0.7482 - val_loss: 0.6122 - val_accuracy: 0.7293\n",
      "Epoch 34/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.5600 - accuracy: 0.7403 - val_loss: 0.5325 - val_accuracy: 0.7560\n",
      "Epoch 35/75\n",
      "70/70 [==============================] - 94s 1s/step - loss: 0.5266 - accuracy: 0.7536 - val_loss: 0.6657 - val_accuracy: 0.7080\n",
      "Epoch 36/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.5342 - accuracy: 0.7522 - val_loss: 0.5641 - val_accuracy: 0.7627\n",
      "Epoch 37/75\n",
      "70/70 [==============================] - 95s 1s/step - loss: 0.5329 - accuracy: 0.7432 - val_loss: 0.5391 - val_accuracy: 0.7573\n",
      "Epoch 38/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.5397 - accuracy: 0.7482 - val_loss: 0.5315 - val_accuracy: 0.7520\n",
      "Epoch 39/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.5295 - accuracy: 0.7592 - val_loss: 0.6504 - val_accuracy: 0.7307\n",
      "Epoch 40/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.5308 - accuracy: 0.7489 - val_loss: 0.5293 - val_accuracy: 0.7600\n",
      "Epoch 41/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.4923 - accuracy: 0.7714 - val_loss: 0.7098 - val_accuracy: 0.6973\n",
      "Epoch 42/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.5427 - accuracy: 0.7480 - val_loss: 0.5591 - val_accuracy: 0.7520\n",
      "Epoch 43/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.5003 - accuracy: 0.7646 - val_loss: 0.6233 - val_accuracy: 0.7453\n",
      "Epoch 44/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.4919 - accuracy: 0.7710 - val_loss: 0.7443 - val_accuracy: 0.7133\n",
      "Epoch 45/75\n",
      "70/70 [==============================] - 99s 1s/step - loss: 0.5022 - accuracy: 0.7728 - val_loss: 0.5233 - val_accuracy: 0.7427\n",
      "Epoch 46/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.5001 - accuracy: 0.7701 - val_loss: 0.5224 - val_accuracy: 0.7480\n",
      "Epoch 47/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.5199 - accuracy: 0.7579 - val_loss: 0.5736 - val_accuracy: 0.7400\n",
      "Epoch 48/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.5098 - accuracy: 0.7618 - val_loss: 0.6065 - val_accuracy: 0.7480\n",
      "Epoch 49/75\n",
      "70/70 [==============================] - 99s 1s/step - loss: 0.5056 - accuracy: 0.7714 - val_loss: 0.6453 - val_accuracy: 0.7280\n",
      "Epoch 50/75\n",
      "70/70 [==============================] - 100s 1s/step - loss: 0.5009 - accuracy: 0.7723 - val_loss: 0.7015 - val_accuracy: 0.7107\n",
      "Epoch 51/75\n",
      "70/70 [==============================] - 99s 1s/step - loss: 0.4897 - accuracy: 0.7777 - val_loss: 0.6934 - val_accuracy: 0.7320\n",
      "Epoch 52/75\n",
      "70/70 [==============================] - 100s 1s/step - loss: 0.4940 - accuracy: 0.7701 - val_loss: 0.7532 - val_accuracy: 0.7147\n",
      "Epoch 53/75\n",
      "70/70 [==============================] - 100s 1s/step - loss: 0.4712 - accuracy: 0.7846 - val_loss: 0.7370 - val_accuracy: 0.7227\n",
      "Epoch 54/75\n",
      "70/70 [==============================] - 101s 1s/step - loss: 0.5045 - accuracy: 0.7656 - val_loss: 0.5168 - val_accuracy: 0.7440\n",
      "Epoch 55/75\n",
      "70/70 [==============================] - 102s 1s/step - loss: 0.4744 - accuracy: 0.7884 - val_loss: 0.6409 - val_accuracy: 0.7400\n",
      "Epoch 56/75\n",
      "70/70 [==============================] - 101s 1s/step - loss: 0.4902 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7667\n",
      "Epoch 57/75\n",
      "70/70 [==============================] - 103s 1s/step - loss: 0.4592 - accuracy: 0.7885 - val_loss: 0.6978 - val_accuracy: 0.7240\n",
      "Epoch 58/75\n",
      "70/70 [==============================] - 111s 2s/step - loss: 0.4519 - accuracy: 0.7926 - val_loss: 0.5402 - val_accuracy: 0.7680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/75\n",
      "70/70 [==============================] - 110s 2s/step - loss: 0.4725 - accuracy: 0.7864 - val_loss: 1.0343 - val_accuracy: 0.6387\n",
      "Epoch 60/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.4638 - accuracy: 0.7902 - val_loss: 0.5136 - val_accuracy: 0.7653\n",
      "Epoch 61/75\n",
      "70/70 [==============================] - 112s 2s/step - loss: 0.4568 - accuracy: 0.7885 - val_loss: 0.5466 - val_accuracy: 0.7613\n",
      "Epoch 62/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.4535 - accuracy: 0.7931 - val_loss: 0.5936 - val_accuracy: 0.7453\n",
      "Epoch 63/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.4725 - accuracy: 0.7750 - val_loss: 0.4923 - val_accuracy: 0.7773\n",
      "Epoch 64/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.4622 - accuracy: 0.7827 - val_loss: 0.5785 - val_accuracy: 0.7507\n",
      "Epoch 65/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.4716 - accuracy: 0.7759 - val_loss: 0.5454 - val_accuracy: 0.7533\n",
      "Epoch 66/75\n",
      "70/70 [==============================] - 114s 2s/step - loss: 0.4667 - accuracy: 0.7858 - val_loss: 0.5236 - val_accuracy: 0.7680\n",
      "Epoch 67/75\n",
      "70/70 [==============================] - 123s 2s/step - loss: 0.4532 - accuracy: 0.8012 - val_loss: 0.6319 - val_accuracy: 0.7413\n",
      "Epoch 68/75\n",
      "70/70 [==============================] - 117s 2s/step - loss: 0.4460 - accuracy: 0.8070 - val_loss: 0.6402 - val_accuracy: 0.7360\n",
      "Epoch 69/75\n",
      "70/70 [==============================] - 118s 2s/step - loss: 0.4556 - accuracy: 0.7904 - val_loss: 0.5146 - val_accuracy: 0.7787\n",
      "Epoch 70/75\n",
      "70/70 [==============================] - 122s 2s/step - loss: 0.4529 - accuracy: 0.7867 - val_loss: 0.5044 - val_accuracy: 0.7773\n",
      "Epoch 71/75\n",
      "70/70 [==============================] - 118s 2s/step - loss: 0.4702 - accuracy: 0.7777 - val_loss: 0.5068 - val_accuracy: 0.7747\n",
      "Epoch 72/75\n",
      "70/70 [==============================] - 116s 2s/step - loss: 0.4456 - accuracy: 0.8079 - val_loss: 0.6921 - val_accuracy: 0.7307\n",
      "Epoch 73/75\n",
      "70/70 [==============================] - 104s 1s/step - loss: 0.4598 - accuracy: 0.7913 - val_loss: 0.7965 - val_accuracy: 0.7120\n",
      "Epoch 74/75\n",
      "70/70 [==============================] - 74s 1s/step - loss: 0.4372 - accuracy: 0.7976 - val_loss: 0.6620 - val_accuracy: 0.7347\n",
      "Epoch 75/75\n",
      "70/70 [==============================] - 69s 992ms/step - loss: 0.4076 - accuracy: 0.8152 - val_loss: 0.7341 - val_accuracy: 0.7213\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    "\n",
    "# initialize the model and optimizer (you'll want to use\n",
    "# binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS) #learning rate decay\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " animals/cats       0.66      0.73      0.69       241\n",
      " animals/dogs       0.74      0.46      0.57       254\n",
      "animals/panda       0.76      0.98      0.85       255\n",
      "\n",
      "     accuracy                           0.72       750\n",
      "    macro avg       0.72      0.72      0.70       750\n",
      " weighted avg       0.72      0.72      0.70       750\n",
      "\n",
      "[INFO] serializing network and label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"plot.jpg\")\n",
    "\n",
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"smallvggmodel\")\n",
    "f = open(\"labelvgg\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
